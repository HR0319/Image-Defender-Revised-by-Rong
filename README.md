# Image-Defender
流程图:
![IMG_2044(20231202-192545)](https://github.com/XuanZhao777/Image-Defender/assets/149707203/5a20a134-1f24-4bac-99b7-c3bab1fab41d)

# 数据库：
CIFAR10

# 攻击部分：
I-FGSM_attack法

# 分离部分:
resnet18模型

# 校正部分:
使用Adam优化器进行迭代优化，用到了均方误差（MSE）损失函数来量化扰动输出和原始输出之间的差异
并不是最高效的

# 结合部分:
简单的相加减去重叠，所以还是可以改进


# 验证部分:
PSNR法验证结合图像与原图像的准确度

解决掉了被攻击中的彩色图像问题，同时也解决了correct_part黑屏问题，既做到了攻击的不被肉眼观察性，同时也将原图实现了一定程度地恢复。
但是由于没有强大的GPU和更多的时间成本，无法在correct部分运用到深度学习的模型训练。
同时攻击的方法太过于单一。

